{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16078,"status":"ok","timestamp":1683854303168,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"umZTsg14CEqH","outputId":"500e0cdd-f4b2-4d22-9878-5c84a9f73091"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Thin-Plate-Spline-Motion-Model'...\n","remote: Enumerating objects: 1147, done.\u001b[K\n","remote: Counting objects: 100% (91/91), done.\u001b[K\n","remote: Compressing objects: 100% (45/45), done.\u001b[K\n","remote: Total 1147 (delta 58), reused 58 (delta 45), pack-reused 1056\u001b[K\n","Receiving objects: 100% (1147/1147), 233.97 MiB | 18.19 MiB/s, done.\n","Resolving deltas: 100% (66/66), done.\n","Updating files: 100% (1035/1035), done.\n"]}],"source":["!git clone https://github.com/yxccxxx/Thin-Plate-Spline-Motion-Model.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1683856196866,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"o6ZacHhoCK6I","outputId":"54a6740a-641a-46a9-d92b-b0ce59e62019"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Thin-Plate-Spline-Motion-Model\n"]}],"source":["cd Thin-Plate-Spline-Motion-Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36535,"status":"ok","timestamp":1683856235682,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"Kd4Wvek1CMfx","outputId":"bcb713c5-243c-4b93-aa81-336b398a4627"},"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘checkpoints’: File exists\n","--2023-05-12 01:49:58--  https://cloud.tsinghua.edu.cn/f/cd411b334a2e49cdb1e2/?dl=1\n","Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 166.111.6.101, 2402:f000:1:406:166:111:6:101\n","Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|166.111.6.101|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cloud.tsinghua.edu.cn/seafhttp/files/9c463bc4-a654-4a1f-8940-0c43add7af58/mgif.pth.tar [following]\n","--2023-05-12 01:50:00--  https://cloud.tsinghua.edu.cn/seafhttp/files/9c463bc4-a654-4a1f-8940-0c43add7af58/mgif.pth.tar\n","Reusing existing connection to cloud.tsinghua.edu.cn:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 306156401 (292M) [application/octet-stream]\n","Saving to: ‘checkpoints/mgif.pth.tar’\n","\n","checkpoints/mgif.pt 100%[===================>] 291.97M  6.72MB/s    in 34s     \n","\n","2023-05-12 01:50:34 (8.68 MB/s) - ‘checkpoints/mgif.pth.tar’ saved [306156401/306156401]\n","\n"]}],"source":["!mkdir checkpoints\n","!wget -c https://cloud.tsinghua.edu.cn/f/cd411b334a2e49cdb1e2/?dl=1 -O checkpoints/mgif.pth.tar"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208707,"status":"ok","timestamp":1683856444358,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"nwkt2Za5JxLB","outputId":"9f2f97f9-d3bd-4d76-b09d-cfbe6a39842c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cffi==1.14.6 (from -r requirements.txt (line 1))\n","  Downloading cffi-1.14.6.tar.gz (475 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting cycler==0.10.0 (from -r requirements.txt (line 2))\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting decorator==5.1.0 (from -r requirements.txt (line 3))\n","  Downloading decorator-5.1.0-py3-none-any.whl (9.1 kB)\n","Collecting face-alignment==1.3.5 (from -r requirements.txt (line 4))\n","  Downloading face_alignment-1.3.5.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting imageio==2.9.0 (from -r requirements.txt (line 5))\n","  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting imageio-ffmpeg==0.4.5 (from -r requirements.txt (line 6))\n","  Downloading imageio_ffmpeg-0.4.5-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kiwisolver==1.3.2 (from -r requirements.txt (line 7))\n","  Downloading kiwisolver-1.3.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting matplotlib==3.4.3 (from -r requirements.txt (line 8))\n","  Downloading matplotlib-3.4.3.tar.gz (37.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting networkx==2.6.3 (from -r requirements.txt (line 9))\n","  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy==1.20.3 (from -r requirements.txt (line 10))\n","  Downloading numpy-1.20.3.zip (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pandas==1.3.3 (from -r requirements.txt (line 11))\n","  Downloading pandas-1.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Pillow==8.3.2 (from -r requirements.txt (line 12))\n","  Downloading Pillow-8.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pycparser==2.20 (from -r requirements.txt (line 13))\n","  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.0/112.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyparsing==2.4.7 (from -r requirements.txt (line 14))\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.8.2)\n","Collecting pytz==2021.1 (from -r requirements.txt (line 16))\n","  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyWavelets==1.1.1 (from -r requirements.txt (line 17))\n","  Downloading PyWavelets-1.1.1.tar.gz (4.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting PyYAML==5.4.1 (from -r requirements.txt (line 18))\n","  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting scikit-image==0.18.3 (from -r requirements.txt (line 19))\n","  Downloading scikit-image-0.18.3.tar.gz (29.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.2/29.2 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting scikit-learn==1.0 (from -r requirements.txt (line 20))\n","  Downloading scikit-learn-1.0.tar.gz (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.0rc1 Requires-Python >=3.7,<3.10; 1.7.0rc2 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.7.1 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.7.2, 1.7.3, 1.8.0rc1, 1.8.0rc2, 1.8.0rc3, 1.8.0rc4, 1.8.0, 1.8.1, 1.9.0rc1, 1.9.0rc2, 1.9.0rc3, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0rc1, 1.10.0rc2, 1.10.0, 1.10.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.7.1\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"bQzcTq3bCJVB"},"source":["# Train model on top of pre-trained model weights\n","--checkpoint: path to checkpoint to restore"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23723798,"status":"ok","timestamp":1683803375237,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"7HXQbMnGCPZm","outputId":"ea1e4f40-8e8d-4b9a-baae-6648951438c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","None\n","Use predefined train-test split.\n","Training...\n","load success: -1\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","  0% 0/20 [00:00<?, ?it/s]Training epoch 0...current time: 2023-05-11 04:34:18.056825\n","  5% 1/20 [19:48<6:16:14, 1188.14s/it]Training epoch 1...current time: 2023-05-11 04:54:06.195395\n"," 10% 2/20 [39:34<5:56:05, 1186.99s/it]Training epoch 2...current time: 2023-05-11 05:13:52.380503\n"," 15% 3/20 [59:18<5:35:59, 1185.84s/it]Training epoch 3...current time: 2023-05-11 05:33:36.846779\n"," 20% 4/20 [1:19:03<5:16:05, 1185.36s/it]Training epoch 4...current time: 2023-05-11 05:53:21.465691\n"," 25% 5/20 [1:38:49<4:56:24, 1185.66s/it]Training epoch 5...current time: 2023-05-11 06:13:07.670819\n"," 30% 6/20 [1:58:34<4:36:33, 1185.24s/it]Training epoch 6...current time: 2023-05-11 06:32:52.099210\n"," 35% 7/20 [2:18:18<4:16:46, 1185.09s/it]Training epoch 7...current time: 2023-05-11 06:52:36.875530\n"," 40% 8/20 [2:38:04<3:57:02, 1185.19s/it]Training epoch 8...current time: 2023-05-11 07:12:22.294080\n"," 45% 9/20 [2:57:49<3:37:16, 1185.18s/it]Training epoch 9...current time: 2023-05-11 07:32:07.441796\n"," 50% 10/20 [3:17:34<3:17:31, 1185.10s/it]Training epoch 10...current time: 2023-05-11 07:51:52.372188\n"," 55% 11/20 [3:37:19<2:57:44, 1184.99s/it]Training epoch 11...current time: 2023-05-11 08:11:37.118171\n"," 60% 12/20 [3:57:03<2:37:59, 1184.94s/it]Training epoch 12...current time: 2023-05-11 08:31:21.936990\n"," 65% 13/20 [4:16:50<2:18:18, 1185.53s/it]Training epoch 13...current time: 2023-05-11 08:51:08.825158\n"," 70% 14/20 [4:36:39<1:58:38, 1186.37s/it]Training epoch 14...current time: 2023-05-11 09:10:57.136418\n"," 75% 15/20 [4:56:24<1:38:51, 1186.20s/it]Training epoch 15...current time: 2023-05-11 09:30:42.956882\n"," 80% 16/20 [5:16:13<1:19:07, 1186.95s/it]Training epoch 16...current time: 2023-05-11 09:50:31.630653\n"," 85% 17/20 [5:35:59<59:20, 1186.73s/it]  Training epoch 17...current time: 2023-05-11 10:10:17.861627\n"," 90% 18/20 [5:55:46<39:33, 1186.67s/it]Training epoch 18...current time: 2023-05-11 10:30:04.371797\n"," 95% 19/20 [6:15:31<19:46, 1186.14s/it]Training epoch 19...current time: 2023-05-11 10:49:49.274746\n","100% 20/20 [6:35:14<00:00, 1185.72s/it]\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 python run.py --config config/mgif-256.yaml --checkpoint checkpoints/mgif.pth.tar --device_ids 0,1"]},{"cell_type":"markdown","metadata":{"id":"zRUlruxE9Oh8"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGj04Zds_MP6"},"outputs":[],"source":["from frames_dataset import FramesDataset\n","from demo import load_checkpoints\n","import os\n","from tqdm import tqdm\n","import torch\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import imageio\n","import yaml\n","from modules.inpainting_network import InpaintingNetwork\n","from modules.bg_motion_predictor import BGMotionPredictor\n","from modules.keypoint_detector import KPDetector\n","from modules.dense_motion import DenseMotionNetwork\n","from modules.avd_network import AVDNetwork\n","\n","def load_model_from_checkpoint(config, checkpoint_path):\n","    inpainting_network = InpaintingNetwork(**config['model_params']['generator_params'],\n","                                           **config['model_params']['common_params'])\n","\n","    if torch.cuda.is_available():\n","        inpainting_network.to(device)\n","\n","    kp_detector = KPDetector(**config['model_params']['common_params'])\n","    dense_motion_network = DenseMotionNetwork(**config['model_params']['common_params'],\n","                                              **config['model_params']['dense_motion_params'])\n","                                                           \n","    if torch.cuda.is_available():\n","        kp_detector.to(device)\n","        dense_motion_network.to(device)\n","\n","    bg_predictor = None\n","    if (config['model_params']['common_params']['bg']):\n","        bg_predictor = BGMotionPredictor()\n","        if torch.cuda.is_available():\n","            bg_predictor.to(device)\n","    \n","    checkpoint = torch.load(checkpoint_path)\n","    if inpainting_network is not None:\n","        inpainting_network.load_state_dict(checkpoint['inpainting_network'])\n","    if kp_detector is not None:\n","        kp_detector.load_state_dict(checkpoint['kp_detector'])\n","    if bg_predictor is not None and 'bg_predictor' in checkpoint:\n","        bg_predictor.load_state_dict(checkpoint['bg_predictor'])\n","    if dense_motion_network is not None:\n","        dense_motion_network.load_state_dict(checkpoint['dense_motion_network'])\n","\n","    return inpainting_network, kp_detector, bg_predictor, dense_motion_network \n","\n","def load_dataset(mode, config_path):\n","    with open(config_path) as f:\n","        config = yaml.safe_load(f)\n","    dataset = FramesDataset(is_train=(mode == 'train'), **config['dataset_params'])\n","    return dataset\n","\n","def reconstruction(config_path, inpainting_network, kp_detector, bg_predictor, dense_motion_network, dataset):\n","    with open(config_path) as f:\n","        config = yaml.safe_load(f)\n","    log_dir = os.path.join('checkpoints')\n","    png_dir = os.path.join(log_dir, 'reconstruction/png')\n","    log_dir = os.path.join(log_dir, 'reconstruction')\n","\n","    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)\n","\n","    if not os.path.exists(log_dir):\n","        os.makedirs(log_dir)\n","\n","    if not os.path.exists(png_dir):\n","        os.makedirs(png_dir)\n","    \n","    loss_list = []\n","    test_loss_per_video = []\n","\n","    inpainting_network.eval()\n","    kp_detector.eval()\n","    dense_motion_network.eval()\n","    if bg_predictor:\n","        bg_predictor.eval()\n","\n","    for it, x in tqdm(enumerate(dataloader)):\n","        with torch.no_grad():\n","            predictions = []\n","            visualizations = []\n","            if torch.cuda.is_available():\n","                x['video'] = x['video'].cuda()\n","            kp_source = kp_detector(x['video'][:, :, 0])\n","            test_loss = 0\n","            for frame_idx in range(x['video'].shape[2]):\n","                source = x['video'][:, :, 0]\n","                driving = x['video'][:, :, frame_idx]\n","                kp_driving = kp_detector(driving)\n","                bg_params = None\n","                if bg_predictor:\n","                    bg_params = bg_predictor(source, driving)\n","                \n","                dense_motion = dense_motion_network(source_image=source, kp_driving=kp_driving,\n","                                                    kp_source=kp_source, bg_param = bg_params, \n","                                                    dropout_flag = False)\n","                out = inpainting_network(source, dense_motion)\n","                out['kp_source'] = kp_source\n","                out['kp_driving'] = kp_driving\n","\n","                predictions.append(np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0])\n","                loss = torch.abs(out['prediction'] - driving).mean().cpu().numpy()\n","                \n","                loss_list.append(loss)\n","                test_loss += loss\n","            # print(np.mean(loss_list))\n","            test_loss_per_video.append(test_loss/x['video'].shape[2])\n","            predictions = np.concatenate(predictions, axis=1)\n","            imageio.imsave(os.path.join(png_dir, x['name'][0] + '.png'), (255 * predictions).astype(np.uint8))\n","    print(\"\\nReconstruction L1 loss: %s\" % np.mean(loss_list))\n","    return test_loss_per_video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaK7zp_4_vpE"},"outputs":[],"source":["device = torch.device('cuda:0')\n","config_path = 'config/mgif-256.yaml'\n","with open(config_path) as f:\n","    config = yaml.safe_load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"zcNf8nRGZSg-","outputId":"6c92fd77-ae74-4649-f02e-91858f98df03"},"outputs":[{"name":"stdout","output_type":"stream","text":["None\n","Use predefined train-test split.\n"]},{"name":"stderr","output_type":"stream","text":["100it [01:41,  1.01s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Reconstruction L1 loss: 0.021064786\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Evaluate model performance with original weights for 20 epoch\n","checkpoint_path = 'checkpoints/00000019-checkpoint.pth.tar'\n","inpainting_network, kp_detector, bg_predictor, dense_motion_network = load_model_from_checkpoint(config, checkpoint_path)\n","dataset = load_dataset('reconstruction', config_path)\n","# Reconstructed videos will be saved to ./checkpoints/reconstruction/png\n","test_loss = reconstruction(config_path, inpainting_network, kp_detector, bg_predictor, dense_motion_network, dataset)"]},{"cell_type":"markdown","source":["# Tune hyperparameters"],"metadata":{"id":"Bv97dTZVJ1F4"}},{"cell_type":"code","source":[" !CUDA_VISIBLE_DEVICES=0,1 python run.py --config config/mgif-256.yaml --checkpoint checkpoints/mgif.pth.tar --device_ids 0,1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AyrutkjPJ3Ws","executionInfo":{"status":"ok","timestamp":1683839027260,"user_tz":240,"elapsed":23774081,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"}},"outputId":"6b9c3749-6d2f-4fa8-a6d3-6d415d66471b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","None\n","Use predefined train-test split.\n","Training...\n","load success: -1\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","  0% 0/20 [00:00<?, ?it/s]Training epoch 0...current time: 2023-05-11 14:27:37.998188\n","  5% 1/20 [19:47<6:16:11, 1187.97s/it]Training epoch 1...current time: 2023-05-11 14:47:25.972606\n"," 10% 2/20 [39:35<5:56:22, 1187.89s/it]Training epoch 2...current time: 2023-05-11 15:07:13.810221\n"," 15% 3/20 [59:23<5:36:35, 1187.96s/it]Training epoch 3...current time: 2023-05-11 15:27:01.839302\n"," 20% 4/20 [1:19:14<5:17:06, 1189.17s/it]Training epoch 4...current time: 2023-05-11 15:46:52.879275\n"," 25% 5/20 [1:39:03<4:57:14, 1188.96s/it]Training epoch 5...current time: 2023-05-11 16:06:41.453688\n"," 30% 6/20 [1:58:51<4:37:22, 1188.78s/it]Training epoch 6...current time: 2023-05-11 16:26:29.884501\n"," 35% 7/20 [2:18:40<4:17:32, 1188.63s/it]Training epoch 7...current time: 2023-05-11 16:46:18.215664\n"," 40% 8/20 [2:38:30<3:57:50, 1189.22s/it]Training epoch 8...current time: 2023-05-11 17:06:08.697520\n"," 45% 9/20 [2:58:21<3:38:06, 1189.68s/it]Training epoch 9...current time: 2023-05-11 17:25:59.379274\n"," 50% 10/20 [3:18:08<3:18:09, 1188.98s/it]Training epoch 10...current time: 2023-05-11 17:45:46.802725\n"," 55% 11/20 [3:37:57<2:58:18, 1188.77s/it]Training epoch 11...current time: 2023-05-11 18:05:35.095295\n"," 60% 12/20 [3:57:47<2:38:34, 1189.29s/it]Training epoch 12...current time: 2023-05-11 18:25:25.559504\n"," 65% 13/20 [4:17:37<2:18:45, 1189.42s/it]Training epoch 13...current time: 2023-05-11 18:45:15.278026\n"," 70% 14/20 [4:37:27<1:58:57, 1189.59s/it]Training epoch 14...current time: 2023-05-11 19:05:05.261981\n"," 75% 15/20 [4:57:14<1:39:05, 1189.02s/it]Training epoch 15...current time: 2023-05-11 19:24:52.955784\n"," 80% 16/20 [5:17:02<1:19:14, 1188.51s/it]Training epoch 16...current time: 2023-05-11 19:44:40.304503\n"," 85% 17/20 [5:36:46<59:22, 1187.36s/it]  Training epoch 17...current time: 2023-05-11 20:04:24.994502\n"," 90% 18/20 [5:56:33<39:34, 1187.04s/it]Training epoch 18...current time: 2023-05-11 20:24:11.280641\n"," 95% 19/20 [6:16:20<19:47, 1187.22s/it]Training epoch 19...current time: 2023-05-11 20:43:58.925716\n","100% 20/20 [6:36:06<00:00, 1188.32s/it]\n"]}]},{"cell_type":"code","source":["checkpoint_path = 'checkpoints/00000019-checkpoint.pth.tar'\n","inpainting_network, kp_detector, bg_predictor, dense_motion_network = load_model_from_checkpoint(config, checkpoint_path)\n","dataset = load_dataset('reconstruction', config_path)\n","# Reconstructed videos will be saved to ./checkpoints/reconstruction/png\n","test_loss = reconstruction(config_path, inpainting_network, kp_detector, bg_predictor, dense_motion_network, dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJvZMsWsvbcV","executionInfo":{"status":"ok","timestamp":1683839151392,"user_tz":240,"elapsed":102680,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"}},"outputId":"05ac872d-4067-40aa-cf2f-1e1302bc6e06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["None\n","Use predefined train-test split.\n"]},{"output_type":"stream","name":"stderr","text":["100it [01:40,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Reconstruction L1 loss: 0.020449812\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LzLCLodro1r8","executionInfo":{"status":"ok","timestamp":1683856007782,"user_tz":240,"elapsed":461,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"}},"outputId":"0cb6e86d-c9b0-4791-deca-3e827ca5f3e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri May 12 01:46:47 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":[" !CUDA_VISIBLE_DEVICES=0,1 python run.py --config config/mgif-256.yaml --checkpoint checkpoints/mgif.pth.tar --device_ids 0,1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaYvf5UO-4SO","executionInfo":{"status":"ok","timestamp":1683887832746,"user_tz":240,"elapsed":23744887,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"}},"outputId":"51ffe49b-eead-4f24-f3d9-21ecf196ddc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","None\n","Use predefined train-test split.\n","Training...\n","load success: -1\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","  0% 0/20 [00:00<?, ?it/s]Training epoch 0...current time: 2023-05-12 04:01:34.088645\n","  5% 1/20 [19:46<6:15:38, 1186.22s/it]Training epoch 1...current time: 2023-05-12 04:21:20.309180\n"," 10% 2/20 [39:30<5:55:34, 1185.27s/it]Training epoch 2...current time: 2023-05-12 04:41:04.908386\n"," 15% 3/20 [59:18<5:36:10, 1186.50s/it]Training epoch 3...current time: 2023-05-12 05:00:52.867682\n"," 20% 4/20 [1:19:04<5:16:20, 1186.25s/it]Training epoch 4...current time: 2023-05-12 05:20:38.743938\n"," 25% 5/20 [1:38:48<4:56:18, 1185.22s/it]Training epoch 5...current time: 2023-05-12 05:40:22.135416\n"," 30% 6/20 [1:58:34<4:36:37, 1185.54s/it]Training epoch 6...current time: 2023-05-12 06:00:08.305597\n"," 35% 7/20 [2:18:21<4:17:00, 1186.20s/it]Training epoch 7...current time: 2023-05-12 06:19:55.867176\n"," 40% 8/20 [2:38:09<3:57:19, 1186.60s/it]Training epoch 8...current time: 2023-05-12 06:39:43.308902\n"," 45% 9/20 [2:57:56<3:37:35, 1186.89s/it]Training epoch 9...current time: 2023-05-12 06:59:30.856523\n"," 50% 10/20 [3:17:44<3:17:50, 1187.05s/it]Training epoch 10...current time: 2023-05-12 07:19:18.255142\n"," 55% 11/20 [3:37:29<2:57:59, 1186.64s/it]Training epoch 11...current time: 2023-05-12 07:39:03.954364\n"," 60% 12/20 [3:57:16<2:38:13, 1186.74s/it]Training epoch 12...current time: 2023-05-12 07:58:50.938305\n"," 65% 13/20 [4:17:04<2:18:28, 1186.93s/it]Training epoch 13...current time: 2023-05-12 08:18:38.296103\n"," 70% 14/20 [4:36:51<1:58:42, 1187.09s/it]Training epoch 14...current time: 2023-05-12 08:38:25.744766\n"," 75% 15/20 [4:56:37<1:38:53, 1186.64s/it]Training epoch 15...current time: 2023-05-12 08:58:11.362165\n"," 80% 16/20 [5:16:25<1:19:08, 1187.16s/it]Training epoch 16...current time: 2023-05-12 09:17:59.723243\n"," 85% 17/20 [5:36:13<59:22, 1187.40s/it]  Training epoch 17...current time: 2023-05-12 09:37:47.672592\n"," 90% 18/20 [5:55:59<39:34, 1187.08s/it]Training epoch 18...current time: 2023-05-12 09:57:34.015755\n"," 95% 19/20 [6:15:46<19:46, 1186.89s/it]Training epoch 19...current time: 2023-05-12 10:17:20.473218\n","100% 20/20 [6:35:34<00:00, 1186.74s/it]\n"]}]},{"cell_type":"code","source":["checkpoint_path = 'checkpoints/00000019-checkpoint.pth.tar'\n","inpainting_network, kp_detector, bg_predictor, dense_motion_network = load_model_from_checkpoint(config, checkpoint_path)\n","dataset = load_dataset('reconstruction', config_path)\n","# Reconstructed videos will be saved to ./checkpoints/reconstruction/png\n","vox_test_loss = reconstruction(config_path, inpainting_network, kp_detector, bg_predictor, dense_motion_network, dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-__JLL5_F8I","executionInfo":{"status":"ok","timestamp":1683892541629,"user_tz":240,"elapsed":119027,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"}},"outputId":"1fd244e4-7c24-423e-be42-46c154b5fafa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["None\n","Use predefined train-test split.\n"]},{"output_type":"stream","name":"stderr","text":["100it [01:55,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Reconstruction L1 loss: 0.02052473\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"2SD4CtlOE1we"},"source":["# Git operations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GoUjpPNgqQgz"},"outputs":[],"source":["!git config --global user.email \"yixincindy19@gmail.com\"\n","!git config --global user.name \"yxccxxx\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_fNehOL7ZzA"},"outputs":[],"source":["!git remote -v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VDL6IU8sDts"},"outputs":[],"source":["# use personal access tokens from https://github.com/settings/tokens\n","!git remote set-url origin https://{access_token}@github.com/yxccxxx/Thin-Plate-Spline-Motion-Model.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1050,"status":"ok","timestamp":1683812175291,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"QQAJt-79E3pJ","outputId":"dbe20ae4-8fee-4157-81e8-c51347686935"},"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n"]}],"source":["!git pull"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":490,"status":"ok","timestamp":1683812166669,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"jb3At0o-9z39","outputId":"f3daa023-be6d-479b-eb4b-8914d4f0d25d"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is ahead of 'origin/main' by 2 commits.\n","  (use \"git push\" to publish your local commits)\n","\n","Changes not staged for commit:\n","  (use \"git add/rm <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mdeleted:    checkpoints/00000000-checkpoint.pth.tar\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}],"source":["!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1683812170363,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"-vCngJtNFTUG","outputId":"a586b235-93b8-4b09-b069-ac5993402d93"},"outputs":[{"output_type":"stream","name":"stdout","text":["[main 36741a1] update from colab\n"," 1 file changed, 0 insertions(+), 0 deletions(-)\n"," delete mode 100644 checkpoints/00000000-checkpoint.pth.tar\n"]}],"source":["!git add -A\n","!git commit -m \"update from colab\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27378,"status":"ok","timestamp":1683812204406,"user":{"displayName":"Cindy Chen","userId":"15581876953272857397"},"user_tz":240},"id":"X-EdQj4mFe1q","outputId":"6bebd3a5-96ad-42cb-dda4-4366a7841189"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 14, done.\n","Counting objects:   7% (1/14)\rCounting objects:  14% (2/14)\rCounting objects:  21% (3/14)\rCounting objects:  28% (4/14)\rCounting objects:  35% (5/14)\rCounting objects:  42% (6/14)\rCounting objects:  50% (7/14)\rCounting objects:  57% (8/14)\rCounting objects:  64% (9/14)\rCounting objects:  71% (10/14)\rCounting objects:  78% (11/14)\rCounting objects:  85% (12/14)\rCounting objects:  92% (13/14)\rCounting objects: 100% (14/14)\rCounting objects: 100% (14/14), done.\n","Delta compression using up to 12 threads\n","Compressing objects:  10% (1/10)\rCompressing objects:  20% (2/10)\rCompressing objects:  30% (3/10)\rCompressing objects:  40% (4/10)\rCompressing objects:  50% (5/10)\rCompressing objects:  60% (6/10)\rCompressing objects:  70% (7/10)\rCompressing objects:  80% (8/10)\rCompressing objects:  90% (9/10)\rCompressing objects: 100% (10/10)\rCompressing objects: 100% (10/10), done.\n","Writing objects:   8% (1/12)\rWriting objects:  16% (2/12)\rWriting objects:  25% (3/12)\rWriting objects:  33% (4/12)\rWriting objects:  50% (6/12)\r^C\n"]}],"source":["!git push"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}